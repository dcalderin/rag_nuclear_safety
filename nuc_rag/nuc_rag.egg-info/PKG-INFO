Metadata-Version: 2.1
Name: nuc-rag
Version: 1.0.0
Summary: Nuclear Safety RAG Application for Technical Data Retrieval and Analysis
Home-page: https://github.com/dcalderin/rag_nuclear_safety
Author: Nuclear Safety RAG Team
Author-email: 
Keywords: nuclear safety,RAG,retrieval-augmented generation,gradio,AI,NLP
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: gradio>=4.0.0
Requires-Dist: openai>=1.0.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: torch>=2.0.0
Requires-Dist: transformers>=4.30.0
Requires-Dist: sentence-transformers>=2.2.2
Requires-Dist: pymupdf>=1.22.0
Requires-Dist: h5py>=3.9.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: openpyxl>=3.0.10
Requires-Dist: tf-keras>=2.16.0

# Nuclear Safety RAG System

A specialized Retrieval-Augmented Generation (RAG) system designed for nuclear safety documentation analysis with enterprise-grade security, multi-vendor flexibility, and regulatory compliance features.

![Nuclear Safety RAG](https://via.placeholder.com/800x400?text=Nuclear+Safety+RAG)

## 🔬 Nuclear Safety Specialization

Built specifically for nuclear regulatory compliance with:
- **Regulatory terminology integration**: GDCs (General Design Criteria), 10 CFRs, PWR/BWR systems
- **Nuclear-specific system prompts**: Pre-configured with nuclear safety knowledge patterns
- **Compliance-ready citations**: Research-grade source attribution for regulatory submissions
- **Example Q&A patterns**: ECCS requirements, containment isolation, emergency procedures

## 🏗️ Unique HDF5-Based Architecture

Unlike traditional RAG systems that only store vector embeddings, this system features a revolutionary **dual-layer storage architecture**:

### **Complete Document Preservation**
```
HDF5 File Structure:
├── document1.pdf (JSON dataset)
│   ├── filename: "PUB2058_web_gsg_18.pdf"
│   ├── link: "file:///full/path/document1.pdf"  
│   └── pages: {
│       1: ["Paragraph 1", "Paragraph 2", ...],
│       2: ["Paragraph 1", "Paragraph 2", ...],
│       ...
│   }
├── document2.pdf (JSON dataset)
└── embeddings.csv (vector database)
```

### **Key Architectural Advantages**
- **📄 Full document structure**: Maintains paragraph-level granularity with page mapping
- **🔗 Clickable navigation**: Direct PDF links with page anchors (`#page=X`)
- **🔒 Local-first security**: Documents never leave your environment
- **📚 Self-contained system**: Everything needed for retrieval in one HDF5 file
- **🔍 Forensic traceability**: Every answer traces back to exact source location

## 🎯 Advanced Citation System

### **Research-Grade Source Attribution**
Each response includes multi-level citations:
- **Verbatim quotes**: Exact text passages from source documents
- **Page precision**: Specific page numbers for verification  
- **Document links**: Clickable `file://` URLs with page anchors
- **Full context**: Original paragraph alongside relevant chunk

### **Citation Data Flow**
```
User Query → Embedding Search → Chunk Retrieval → Context Assembly → LLM Response + Citations
     ↓                ↓              ↓               ↓                    ↓
 "What is ECCS?" → Vector Match → Source Chunks → Full Paragraphs → "Based on 10 CFR 50.46..."
                                      ↓               ↓                    ↓
                               Page tracking → File links → [Document.pdf, Page 23]
```

## 🔄 Multi-Vendor Flexibility

### **LLM Provider Options** (9 Configurations)
| Provider | Model | Context Window | Use Case |
|----------|-------|---------------|----------|
| **Azure OpenAI** | AzureGPT | 4K tokens | Enterprise compliance |
| **OpenAI** | gpt-4o | 8K tokens | High performance |
| **OpenAI** | gpt-4o-turbo | 128K tokens | Complex documents |
| **OpenAI** | gpt-4o-mini | 4K tokens | Cost-effective |
| **OpenAI** | gpt-3.5-turbo variants | 2K-4K tokens | Fast processing |

### **Embedding Provider Options** (3 Architectures)
| Provider | Model | Dimensions | Deployment |
|----------|-------|------------|------------|
| **Azure OpenAI** | text-embedding-ada-002 | 1536 | Cloud |
| **OpenAI** | text-embedding-ada-002 | 1536 | Cloud |
| **SentenceTransformers** | all-MiniLM-L6-v2 | 384 | Local/Offline |
| **Custom** | atomic-canyon-fermi-nrc | 768 | Local/Specialized |

### **Strategic Advantages**
- **🔄 Vendor independence**: No lock-in to any single provider
- **💰 Cost optimization**: Choose based on budget/performance needs  
- **🔐 Security compliance**: Local embeddings for classified environments
- **⚡ Failover capability**: Switch providers if one becomes unavailable
- **🎛️ Performance tuning**: Mix and match for optimal results
- **🔮 Future-proof**: Easy to add new models as they become available

## 📊 Intelligent Auto-Configuration

Each model combination automatically optimizes:
- **Chunk sizes**: 256-8000 tokens based on model capacity
- **Overlap parameters**: 50-500 tokens for context preservation  
- **Context windows**: 2K-128K tokens depending on model
- **Temperature/token limits**: Pre-tuned for nuclear safety responses

## 🔒 Security & Compliance Features

- **📄 Document isolation**: Only user queries sent to external APIs, never document content
- **🏠 Local vector storage**: HDF5 database remains in your environment
- **✈️ Air-gap compatibility**: Supports local embedding models for offline operation
- **🔐 Regulatory compliance**: Built for security-sensitive nuclear documentation
- **📋 Audit trails**: Complete provenance tracking for all responses

## Architecture Overview

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│                 │     │                 │     │                 │
│  PDF Documents  │────▶│ HDF5 Constructor│────▶│ Multi-Provider  │
│                 │     │  (Paragraphs +  │     │   Embeddings    │
│                 │     │   Page Mapping) │     │                 │
└─────────────────┘     └─────────────────┘     └─────────────────┘
                                                         │
                                                         ▼
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│                 │     │                 │     │                 │
│   User Query    │────▶│ Similarity      │◀────│ HDF5 Vector     │
│                 │     │ Search Engine   │     │ Database        │
│                 │     │                 │     │                 │
└─────────────────┘     └─────────────────┘     └─────────────────┘
                                 │
                                 ▼
                        ┌─────────────────┐
                        │ Multi-LLM       │
                        │ Response with   │
                        │ Research-Grade  │
                        │ Citations       │
                        └─────────────────┘
```

## Installation

### Prerequisites

- Python 3.8+
- PyTorch (for local embedding models)
- One or more API keys:
  - Azure OpenAI API key (for Azure models)
  - OpenAI API key (for OpenAI models)
  - Or use local models only (no API keys needed)

### Setup

1. Clone the repository:

```bash
git clone https://github.com/dcalderin/rag_nuclear_safety.git
cd rag_nuclear_safety
```

2. Create and activate a virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Set up environment variables (create `.env` file):

```bash
# Azure OpenAI (optional)
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
AZURE_OPENAI_KEY=your_azure_openai_key
AZURE_EMB_ENDPOINT=your_azure_embedding_endpoint
AZURE_EMB_API_KEY=your_azure_embedding_api_key
AZURE_VERSION=2024-05-01-preview

# OpenAI (optional)
OPENAI_API_KEY=your_openai_api_key

# Note: Local models (all-MiniLM-L6-v2, atomic-canyon-fermi-nrc) 
# work without any API keys
```

## Usage

### Quick Start

```bash
python gradio_app.py
```

Access the interface at: **http://localhost:7860**

### Two-Tab Interface

#### **1. Set Up Tab**: Document Processing
- **📁 Upload PDFs**: Multi-file support for nuclear documentation
- **🤖 Choose Models**: Select LLM provider (Azure/OpenAI) and embedding model
- **⚙️ Auto-tune Parameters**: System automatically optimizes chunk size and overlap
- **🔄 Process**: Creates HDF5 database with complete document structure + embeddings

#### **2. Ask Question Tab**: Nuclear Safety Q&A
- **❓ Enter Query**: Natural language questions about your documents
- **🎯 Set Similarity**: Adjust retrieval threshold (percentage-based filtering)
- **📋 Get Answer**: Response with research-grade citations and source verification

### Example Queries
- "What are the requirements for containment isolation in PWRs?"
- "Explain the ECCS acceptance criteria per 10 CFR 50.46"
- "What is the regulatory basis for emergency core cooling systems?"

## File Structure & Components

| File | Purpose |
|------|---------|
| `gradio_app.py` | **Main interface** - Gradio web UI with multi-model configuration |
| `hdf5_file_constructor.py` | **Document processor** - PDF→HDF5 with paragraph structure |
| `embeddings.py` | **Multi-provider embeddings** - Azure/OpenAI/Local model support |
| `azure_gpt.py` | **LLM integration** - Multi-vendor response generation |
| `custom_embed.py` | **Custom models** - Specialized nuclear domain embeddings |
| `chunks.py` | **Text processing** - Advanced chunking with overlap strategies |

## Advanced Features

### **📊 Analysis & Export**
- Similarity ranking export to Excel (`ranked_chunk_all.xlsx`)
- Query-specific result exports (`ranked_chunkto{query}.csv`)
- Debug output for embedding analysis

### **🎨 Professional Interface**
- Nuclear industry-themed UI design
- LaTeX math rendering support (`$...$` and `$$...$$`)
- Real-time parameter adjustment
- Professional color scheme and typography

### **🔧 Customization Options**

#### Add New LLM Models
```python
LLM_CONFIGS["new-model"] = {
    "max_tokens": 4096,
    "dimension": 1024,
    "recommended_chunk": 2000,
    "overlap": 300
}
```

#### Add New Embedding Models
```python
MODEL_CONFIGS["new-embedding"] = {
    "max_tokens": 512,
    "dimension": 768,
    "recommended_chunk": 400,
    "overlap": 100
}
```

## Enterprise Deployment

### **Air-Gapped Environments**
1. Use local embedding models (`all-MiniLM-L6-v2` or `atomic-canyon-fermi-nrc`)
2. Deploy local LLM server (compatible with OpenAI API format)
3. Process documents entirely offline
4. Only LLM inference requires connectivity (or can be local)

### **Hybrid Cloud Setup**
- Embeddings: Local processing for document security
- LLM: Cloud-based for latest models and performance
- Storage: Local HDF5 for complete data control

## Contributing

Contributions welcome! Key areas for enhancement:
- Additional embedding model integrations
- New LLM provider support
- Enhanced nuclear safety domain knowledge
- Advanced citation formatting
- Performance optimizations

## License

[MIT License](LICENSE)

## Contact

For questions or collaboration opportunities, please open an issue on GitHub.

---

*Designed for nuclear safety professionals requiring regulatory compliance, source verification, and enterprise-grade security.*
